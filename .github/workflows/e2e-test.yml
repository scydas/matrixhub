name: E2E test

on:
  push:
    branches:
      - main
    paths:
      - 'cmd/**'
      - 'internal/**'
      - 'pkg/**'

  pull_request:
    branches:
      - main
    paths:
      - 'cmd/**'
      - 'internal/**'
      - 'pkg/**'

# Copy from https://github.com/vllm-project/vllm/blob/b66b0d6abb955f9209a0d88b1dc245f4c1c9ff98/.github/workflows/macos-smoke-test.yml
# modified to test against MatrixHub

jobs:
  e2e-test:
    runs-on: macos-latest
    timeout-minutes: 30

    concurrency:
      group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
      cancel-in-progress: true

    steps:
      - uses: actions/checkout@v6

      - name: Set up Go
        uses: actions/setup-go@v6
        with:
          go-version-file: go.mod

      - name: Cache Go modules
        uses: actions/cache@v5
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-

      - run: |
          go build -o matrixhub ./cmd/poc

          ./matrixhub --addr=:9527 &

          sleep 10

          echo "Importing Qwen/Qwen3-0.6B model from Hugging Face..."
          curl -X POST "http://localhost:9527/api/repositories/localcache/Qwen3-0.6B.git/import" -d '{
            "source_url": "https://huggingface.co/Qwen/Qwen3-0.6B"
          }'


      - uses: actions/checkout@v6
        with:
          repository: vllm-project/vllm
          ref: v0.13.0
          path: vllm

      - uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true
          cache-dependency-glob: |
            vllm/requirements/**/*.txt
            vllm/pyproject.toml
          python-version: "3.12"

      - name: Create virtual environment
        run: |
          uv venv
          echo "$GITHUB_WORKSPACE/.venv/bin" >> "$GITHUB_PATH"

      - name: Install dependencies and build vLLM
        run: |
          uv pip install -r vllm/requirements/cpu.txt --index-strategy unsafe-best-match
          uv pip install -e vllm
        env:
          CMAKE_BUILD_PARALLEL_LEVEL: 4

      - name: Test vllm serve
        run: |
          # Start server in background
          HF_ENDPOINT=http://localhost:9527 vllm serve localcache/Qwen3-0.6B \
            --max-model-len=2K \
            --load-format=dummy \
            --hf-overrides '{"num_hidden_layers": 2}' \
            --enforce-eager \
            --port 8000 &

          SERVER_PID=$!

          # Wait for server to start
          for i in {1..30}; do
            if curl -s http://localhost:8000/health > /dev/null; then
              echo "Server started successfully"
              break
            fi
            if [ "$i" -eq 30 ]; then
              echo "Server failed to start"
              kill "$SERVER_PID"
              exit 1
            fi
            sleep 2
          done

          # Test health endpoint
          curl -f http://localhost:8000/health

          # Test completion
          curl -f http://localhost:8000/v1/completions \
            -H "Content-Type: application/json" \
            -d '{
              "model": "localcache/Qwen3-0.6B",
              "prompt": "Hello",
              "max_tokens": 5
            }'

          # Cleanup
          kill "$SERVER_PID"
